{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport numpy as np\nfrom os import path,getcwd\nfrom PIL import Image\nfrom wordcloud import ImageColorGenerator,WordCloud,STOPWORDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/disaster-tweets/tweets.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data[[\"text\",\"target\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ham=data[data[\"target\"]==1]\nham1=ham[\"text\"].to_string()\nword=WordCloud().generate(ham1)\nplt.imshow(word,interpolation=\"blackman\")\nplt.axis(\"off\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ham2=data[\"text\"].to_string()\nimage=np.array(Image.open(\"../input/images-white/7030439_preview.png\"))\nword=WordCloud(background_color=\"white\",mask=image,max_font_size=80,max_words=2000,random_state=1)\nword.generate(ham2)\nplt.figure(figsize=[15,15])\nplt.imshow(word,interpolation=\"blackman\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom nltk.stem  import WordNetLemmatizer\nfrom wordcloud import WordCloud,ImageColorGenerator,STOPWORDS\nfrom os import path, getcwd\nfrom PIL import Image\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nimport re,string,unicodedata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load stop words\nstop_word = stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean(text):\n    text=re.sub(r\"#\\w+\",\" \",text)\n    text=re.sub(r\"@\\w+\",\" \",text)\n    text=re.sub(r\"\\d+\",\" \",text)\n    text=re.sub(r\"http\\S+\",\" \",text)\n    text=re.sub(\"r<?.*>\",\" \",text)\n    text=text.split()\n    text=\" \".join([word for word in text if not word in stop_word])\n    return text    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"text\"]=data[\"text\"].apply(lambda x:clean(x))\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Removing Special Charachters:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nstring.punctuation\nre_punc = re.compile('[%s]' % re.escape(string.punctuation))\ndata[\"text\"]=[re_punc.sub(\" \",w) for w in data[\"text\"]]\ndata[\"text\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Upper to Lower:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"text\"]=[word.lower() for word in data[\"text\"]]\ndata[\"text\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=np.array(data[\"text\"])\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=np.array(data[\"target\"])\ny\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer()\nprint(cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set=cv.fit_transform(x_train)\ntest_set=cv.transform(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set.toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nMachine=MultinomialNB()\nMachine.fit(train_set,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Prediction=Machine.predict(test_set)\nPrediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,classification_report,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(Prediction,y_test)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Machine.score(train_set,y_train)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(Prediction,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(Prediction,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.countplot(data[\"target\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1))) \n    print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0))) \n\n    # import SMOTE module from imblearn library \n    # pip install imblearn (if you don't have imblearn in your system) \n    from imblearn.over_sampling import SMOTE \n    sm = SMOTE(random_state = 42) \n    x_train_res, y_train_res = sm.fit_sample(train_set, y_train)   #y_train.ravel() \n\n    print('After OverSampling, the shape of train_X: {}'.format(x_train_res.shape)) \n    print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape)) \n\n     \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1=MultinomialNB()\nmodel1.fit(x_train_res,y_train_res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred2=model1.predict(test_set)\npred2[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(y_test,pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_score(pred2,y_test)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.score(x_train_res,y_train_res)*100","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}